from flask import Flask, request, jsonify
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
import os
from flask_cors import CORS
from pyspark.sql import functions as F

os.environ['PYSPARK_PYTHON'] = 'python'
app = Flask(__name__)

CORS(app)

# Khá»Ÿi táº¡o Spark session
print("ğŸ”„ Äang khá»Ÿi táº¡o Spark session...")
spark = SparkSession.builder \
    .appName("StrokeRiskPrediction") \
    .config("spark.executor.memory", "2g") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.cores", "1") \
    .config("spark.python.worker.faulthandler.enabled", "true") \
    .config("spark.sql.execution.pyspark.udf.faulthandler.enabled", "true") \
    .getOrCreate()

# spark = SparkSession.builder.appName("StrokeRiskPrediction").getOrCreate()
print("âœ… Spark session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o.")

# ÄÆ°á»ng dáº«n tá»›i model
current_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(current_dir, "models", "Model_LogisticRegression")

# Load PipelineModel thay vÃ¬ LogisticRegressionModel
print(f"ğŸ”„ Äang load model tá»«: {model_path}")
model = PipelineModel.load(model_path)
print("âœ… Model Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng.")

@app.route('/api/predict', methods=['POST'])
def predict():
    print("\nğŸ“¥ Nháº­n yÃªu cáº§u dá»± Ä‘oÃ¡n tá»« client...")
    data = request.json
    if not data:
        print("âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u Ä‘áº§u vÃ o.")
        return jsonify({"error": "No input data received"}), 400
    print("Dá»¯ liá»‡u nháº­n Ä‘Æ°á»£c tá»« client:", data)

    try:
        input_columns = ['Sex','GeneralHealth','HeightInMeters','WeightInKilograms','BMI',
        'HadHeartAttack','HadAngina','HadStroke','HadAsthma','HadSkinCancer','HadCOPD',
        'HadDepressiveDisorder','HadKidneyDisease','HadArthritis','DeafOrHardOfHearing',
        'BlindOrVisionDifficulty','DifficultyConcentrating','DifficultyWalking',
        'DifficultyDressingBathing','DifficultyErrands','SmokerStatus','ECigaretteUsage',
        'ChestScan','AlcoholDrinkers','HIVTesting','FluVaxLast12','PneumoVaxEver',
        'HighRiskLastYear','CovidPos','AgeMin','AgeMax','TetanusLast10TdapIndex',
        'HadDiabetesIndex']

        # Táº¡o Spark DataFrame tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o
        df = spark.createDataFrame([[data[col] for col in input_columns]], input_columns)
        print("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn thÃ nh DataFrame.")
        df.printSchema()

        print("ğŸ” Äang cháº¡y pipeline transform + dá»± Ä‘oÃ¡n...")
        result_row = model.transform(df).take(1)[0]

        prediction = result_row.prediction
        probability = result_row.probability[1]  # XÃ¡c suáº¥t nhÃ£n 1 (cÃ³ nguy cÆ¡ cao)

        label_map = {0.0: "Low Risk", 1.0: "High Risk"}

        result = {
            "prediction": label_map.get(prediction, str(prediction)),
            "probability": round(float(probability) * 100, 2)
        }

        print(f"ğŸ“¤ Káº¿t quáº£ dá»± Ä‘oÃ¡n gá»­i vá» client: {result}")
        return jsonify(result)

    except Exception as e:
        print("âŒ Lá»—i khi dá»± Ä‘oÃ¡n:", e)
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    print("Flask API Ä‘ang cháº¡y...")
    app.run(host='0.0.0.0', port=5000, debug=True)