from flask import Flask, request, jsonify
from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
import os
from flask_cors import CORS
from pyspark.sql import functions as F
from tensorflow.keras.models import load_model
import numpy as np
from PIL import Image
import base64
import io
from io import BytesIO
import re

os.environ['PYSPARK_PYTHON'] = 'python'
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB, Ä‘iá»u chá»‰nh theo nhu cáº§u

CORS(app)

# Khá»Ÿi táº¡o Spark session
print("ğŸ”„ Äang khá»Ÿi táº¡o Spark session...")
spark = SparkSession.builder \
    .appName("StrokeRiskPrediction") \
    .config("spark.executor.memory", "2g") \
    .config("spark.driver.memory", "2g") \
    .config("spark.executor.cores", "1") \
    .config("spark.python.worker.faulthandler.enabled", "true") \
    .config("spark.sql.execution.pyspark.udf.faulthandler.enabled", "true") \
    .getOrCreate()

# spark = SparkSession.builder.appName("StrokeRiskPrediction").getOrCreate()
print("âœ… Spark session Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o.")

# ÄÆ°á»ng dáº«n tá»›i model
current_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(current_dir, "models", "Model_LogisticRegression")

# Load PipelineModel thay vÃ¬ LogisticRegressionModel
print(f"ğŸ”„ Äang load model Logistic RegressionModel tá»«: {model_path}")
model = PipelineModel.load(model_path)
print("âœ… Model Logistic RegressionModel Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng.")

# ÄÆ°á»ng dáº«n model VGG16
vgg_model_path = os.path.join(current_dir, "models", "vgg16_model.h5")
print(f"ğŸ”„ Äang load model VGG16 tá»«: {vgg_model_path}")
vgg_model = load_model(vgg_model_path)
print("âœ… Model VGG16 Ä‘Ã£ Ä‘Æ°á»£c load thÃ nh cÃ´ng.")

def preprocess_image(image_base64):
    try:
        image_data = base64.b64decode(image_base64)
        image = Image.open(io.BytesIO(image_data)).convert("RGB")
        image = image.resize((224, 224))  # KÃ­ch thÆ°á»›c chuáº©n cá»§a VGG16
        image_array = np.array(image) / 255.0
        return np.expand_dims(image_array, axis=0)  # (1, 224, 224, 3)
    except Exception as e:
        raise ValueError(f"Error processing image: {str(e)}")

@app.route('/api/predict', methods=['POST'])
def predict():
    print("\nğŸ“¥ Nháº­n yÃªu cáº§u dá»± Ä‘oÃ¡n tá»« client...")
    data = request.json
    if not data:
        print("âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u Ä‘áº§u vÃ o.")
        return jsonify({"error": "No input data received"}), 400
    print("Dá»¯ liá»‡u nháº­n Ä‘Æ°á»£c tá»« client:", data)

    try:
        input_columns = ['Sex','GeneralHealth','HeightInMeters','WeightInKilograms','BMI',
        'HadHeartAttack','HadAngina','HadStroke','HadAsthma','HadSkinCancer','HadCOPD',
        'HadDepressiveDisorder','HadKidneyDisease','HadArthritis','DeafOrHardOfHearing',
        'BlindOrVisionDifficulty','DifficultyConcentrating','DifficultyWalking',
        'DifficultyDressingBathing','DifficultyErrands','SmokerStatus','ECigaretteUsage',
        'ChestScan','AlcoholDrinkers','HIVTesting','FluVaxLast12','PneumoVaxEver',
        'HighRiskLastYear','CovidPos','AgeMin','AgeMax','TetanusLast10TdapIndex',
        'HadDiabetesIndex']

        # Táº¡o Spark DataFrame tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o
        df = spark.createDataFrame([[data[col] for col in input_columns]], input_columns)
        print("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuyá»ƒn thÃ nh DataFrame.")
        result_row = model.transform(df).take(1)[0]
        spark_prob = float(result_row.probability[1])
        print(f"âœ… Model Logistic RegressionModel dá»± Ä‘oÃ¡n xÃ¡c suáº¥t lÃ : {spark_prob}")

        # ==== 2. Tiá»n xá»­ lÃ½ áº£nh vÃ  dá»± Ä‘oÃ¡n báº±ng VGG16 model ====
        image_base64 = data.get("image_base64", None)
        if image_base64 is None:
            raise ValueError("KhÃ´ng nháº­n Ä‘Æ°á»£c áº£nh (image_base64).")
        
        processed_image = preprocess_image(image_base64)
        vgg_prob = float(vgg_model.predict(processed_image)[0][0])  # giáº£ sá»­ output lÃ  sigmoid
        print(f"âœ… model VGG16 dá»± Ä‘oÃ¡n xÃ¡c suáº¥t lÃ : {vgg_prob}")

        # ==== 3. Trung bÃ¬nh káº¿t quáº£ ====
        avg_prob = (spark_prob + vgg_prob) / 2
        prediction = 1.0 if avg_prob >= 0.5 else 0.0

        label_map = {0.0: "Low Risk", 1.0: "High Risk"}
        result = {
            "prediction": label_map[prediction],
            "average_probability": round(avg_prob * 100, 2),
            "spark_probability": round(spark_prob * 100, 2),
            "vgg_probability": round(vgg_prob * 100, 2),
        }

        print(f"ğŸ“¤ Káº¿t quáº£ dá»± Ä‘oÃ¡n gá»­i vá» client: {result}")
        return jsonify(result)

    except Exception as e:
        print("âŒ Lá»—i khi dá»± Ä‘oÃ¡n:", e)
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    print("Flask API Ä‘ang cháº¡y...")
    app.run(host='0.0.0.0', port=5000, debug=True)